{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripción\n",
    "El servicio de venta de autos usados Rusty Bargain está desarrollando una aplicación para atraer nuevos clientes. Gracias a esa app, puedes averiguar rápidamente el valor de mercado de tu coche. Tienes acceso al historial: especificaciones técnicas, versiones de equipamiento y precios. Tienes que crear un modelo que determine el valor de mercado.\n",
    "A Rusty Bargain le interesa:\n",
    "- la calidad de la predicción;\n",
    "- la velocidad de la predicción;\n",
    "- el tiempo requerido para el entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías y modulos generales\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos dataset\n",
    "df = pd.read_csv('car_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateCrawled</th>\n",
       "      <th>Price</th>\n",
       "      <th>VehicleType</th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Gearbox</th>\n",
       "      <th>Power</th>\n",
       "      <th>Model</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>FuelType</th>\n",
       "      <th>Brand</th>\n",
       "      <th>NotRepaired</th>\n",
       "      <th>DateCreated</th>\n",
       "      <th>NumberOfPictures</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>LastSeen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>322923</th>\n",
       "      <td>07/03/2016 11:50</td>\n",
       "      <td>5290</td>\n",
       "      <td>wagon</td>\n",
       "      <td>2003</td>\n",
       "      <td>manual</td>\n",
       "      <td>131</td>\n",
       "      <td>a4</td>\n",
       "      <td>150000</td>\n",
       "      <td>2</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>audi</td>\n",
       "      <td>no</td>\n",
       "      <td>07/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>71686</td>\n",
       "      <td>15/03/2016 05:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91219</th>\n",
       "      <td>15/03/2016 22:52</td>\n",
       "      <td>12480</td>\n",
       "      <td>wagon</td>\n",
       "      <td>2005</td>\n",
       "      <td>manual</td>\n",
       "      <td>231</td>\n",
       "      <td>3er</td>\n",
       "      <td>150000</td>\n",
       "      <td>12</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>bmw</td>\n",
       "      <td>no</td>\n",
       "      <td>15/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>87549</td>\n",
       "      <td>16/03/2016 01:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42317</th>\n",
       "      <td>01/04/2016 23:50</td>\n",
       "      <td>4500</td>\n",
       "      <td>bus</td>\n",
       "      <td>2006</td>\n",
       "      <td>manual</td>\n",
       "      <td>131</td>\n",
       "      <td>scenic</td>\n",
       "      <td>125000</td>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>renault</td>\n",
       "      <td>no</td>\n",
       "      <td>01/04/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>44579</td>\n",
       "      <td>06/04/2016 02:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285345</th>\n",
       "      <td>11/03/2016 17:56</td>\n",
       "      <td>3995</td>\n",
       "      <td>small</td>\n",
       "      <td>2007</td>\n",
       "      <td>manual</td>\n",
       "      <td>80</td>\n",
       "      <td>corsa</td>\n",
       "      <td>150000</td>\n",
       "      <td>3</td>\n",
       "      <td>petrol</td>\n",
       "      <td>opel</td>\n",
       "      <td>no</td>\n",
       "      <td>11/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>26670</td>\n",
       "      <td>05/04/2016 18:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195950</th>\n",
       "      <td>29/03/2016 09:36</td>\n",
       "      <td>550</td>\n",
       "      <td>bus</td>\n",
       "      <td>2001</td>\n",
       "      <td>manual</td>\n",
       "      <td>107</td>\n",
       "      <td>scenic</td>\n",
       "      <td>150000</td>\n",
       "      <td>4</td>\n",
       "      <td>petrol</td>\n",
       "      <td>renault</td>\n",
       "      <td>yes</td>\n",
       "      <td>29/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>84389</td>\n",
       "      <td>31/03/2016 03:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DateCrawled  Price VehicleType  RegistrationYear Gearbox  Power  \\\n",
       "322923  07/03/2016 11:50   5290       wagon              2003  manual    131   \n",
       "91219   15/03/2016 22:52  12480       wagon              2005  manual    231   \n",
       "42317   01/04/2016 23:50   4500         bus              2006  manual    131   \n",
       "285345  11/03/2016 17:56   3995       small              2007  manual     80   \n",
       "195950  29/03/2016 09:36    550         bus              2001  manual    107   \n",
       "\n",
       "         Model  Mileage  RegistrationMonth  FuelType    Brand NotRepaired  \\\n",
       "322923      a4   150000                  2  gasoline     audi          no   \n",
       "91219      3er   150000                 12  gasoline      bmw          no   \n",
       "42317   scenic   125000                  1  gasoline  renault          no   \n",
       "285345   corsa   150000                  3    petrol     opel          no   \n",
       "195950  scenic   150000                  4    petrol  renault         yes   \n",
       "\n",
       "             DateCreated  NumberOfPictures  PostalCode          LastSeen  \n",
       "322923  07/03/2016 00:00                 0       71686  15/03/2016 05:16  \n",
       "91219   15/03/2016 00:00                 0       87549  16/03/2016 01:42  \n",
       "42317   01/04/2016 00:00                 0       44579  06/04/2016 02:44  \n",
       "285345  11/03/2016 00:00                 0       26670  05/04/2016 18:46  \n",
       "195950  29/03/2016 00:00                 0       84389  31/03/2016 03:15  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisamos muestra de dataset e info\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 354369 entries, 0 to 354368\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   DateCrawled        354369 non-null  object\n",
      " 1   Price              354369 non-null  int64 \n",
      " 2   VehicleType        316879 non-null  object\n",
      " 3   RegistrationYear   354369 non-null  int64 \n",
      " 4   Gearbox            334536 non-null  object\n",
      " 5   Power              354369 non-null  int64 \n",
      " 6   Model              334664 non-null  object\n",
      " 7   Mileage            354369 non-null  int64 \n",
      " 8   RegistrationMonth  354369 non-null  int64 \n",
      " 9   FuelType           321474 non-null  object\n",
      " 10  Brand              354369 non-null  object\n",
      " 11  NotRepaired        283215 non-null  object\n",
      " 12  DateCreated        354369 non-null  object\n",
      " 13  NumberOfPictures   354369 non-null  int64 \n",
      " 14  PostalCode         354369 non-null  int64 \n",
      " 15  LastSeen           354369 non-null  object\n",
      "dtypes: int64(7), object(9)\n",
      "memory usage: 43.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formateo de columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DateCrawled': 'datecrawled', 'Price': 'price',\n",
       "       'VehicleType': 'vehicletype', 'RegistrationYear': 'registrationyear',\n",
       "       'Gearbox': 'gearbox', 'Power': 'power', 'Model': 'model',\n",
       "       'Mileage': 'mileage', 'RegistrationMonth': 'registrationmonth',\n",
       "       'FuelType': 'fueltype', 'Brand': 'brand', 'NotRepaired': 'notrepaired',\n",
       "       'DateCreated': 'datecreated', 'NumberOfPictures': 'numberofpictures',\n",
       "       'PostalCode': 'postalcode', 'LastSeen': 'lastseen'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Atajo para renombrar columnas\n",
    "df.columns + \"'\" + \": \" + \"'\" + df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formateamos nombres de columnas\n",
    "df = df.rename(columns={'DateCrawled': 'date_crawled', 'Price': 'price', 'VehicleType': 'vehicle_type',\n",
    "                        'RegistrationYear': 'reg_year', 'Gearbox': 'gearbox', 'Power': 'power',\n",
    "                        'Model': 'model', 'Mileage': 'mileage', 'RegistrationMonth': 'reg_month',\n",
    "                        'FuelType': 'fuel_type', 'Brand': 'brand', 'NotRepaired': 'not_repaired',\n",
    "                        'DateCreated': 'date_created', 'NumberOfPictures': 'number_of_pictures',\n",
    "                        'PostalCode': 'postal_code', 'LastSeen': 'last_seen_date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_crawled</th>\n",
       "      <th>date_created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2016-03-24 00:52:00</td>\n",
       "      <td>2016-03-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2016-04-04 00:38:00</td>\n",
       "      <td>2016-03-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2016-03-21 12:47:00</td>\n",
       "      <td>2016-09-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2016-03-28 00:56:00</td>\n",
       "      <td>2016-03-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>2016-03-21 00:59:00</td>\n",
       "      <td>2016-03-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date_crawled date_created\n",
       "42  2016-03-24 00:52:00   2016-03-23\n",
       "47  2016-04-04 00:38:00   2016-03-04\n",
       "67  2016-03-21 12:47:00   2016-09-02\n",
       "99  2016-03-28 00:56:00   2016-03-27\n",
       "178 2016-03-21 00:59:00   2016-03-20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Realizamos prueba para saber si la fecha de descarga es la misma que la fecha de creación\n",
    "df['date_crawled'] = pd.to_datetime(df['date_crawled'])\n",
    "df['date_created'] = pd.to_datetime(df['date_created'])\n",
    "df['last_seen_date'] = pd.to_datetime(df['last_seen_date'])\n",
    "\n",
    "df[['date_crawled', 'date_created']][df['date_crawled'].dt.date !=\n",
    "                                     df['date_created'].dt.date].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al saber que si hay fechas diferentes eliminaremos una columna, en este caso 'date_crawled' no nos sirve para nuesto análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregamos columnas necesarias\n",
    "df['postal_region'] = df['postal_code'] // 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date_crawled', 'price', 'vehicle_type', 'reg_year', 'gearbox', 'power',\n",
       "       'model', 'mileage', 'reg_month', 'fuel_type', 'brand', 'not_repaired',\n",
       "       'date_created', 'number_of_pictures', 'postal_code', 'last_seen_date',\n",
       "       'postal_region'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordenamos columnas y eliminamos las que no aportan al análisis\n",
    "selected_ordered_columns = ['date_created', 'price', 'reg_year', 'reg_month', 'mileage', 'brand',\n",
    "                            'model', 'vehicle_type', 'gearbox', 'power', 'fuel_type', 'not_repaired',\n",
    "                            'postal_region', 'last_seen_date']\n",
    "df = df[selected_ordered_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eliminaron las columnas 'date_crawled' (dato técnico) y 'number_of_pictures' (columnas todas en '0') dado que no aportan información necesaria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamiento de filas duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas duplicadas: 1082\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_created</th>\n",
       "      <th>price</th>\n",
       "      <th>reg_year</th>\n",
       "      <th>reg_month</th>\n",
       "      <th>mileage</th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>vehicle_type</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>power</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>not_repaired</th>\n",
       "      <th>postal_region</th>\n",
       "      <th>last_seen_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>237989</th>\n",
       "      <td>2016-03-19</td>\n",
       "      <td>16450</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>60000</td>\n",
       "      <td>seat</td>\n",
       "      <td>leon</td>\n",
       "      <td>sedan</td>\n",
       "      <td>manual</td>\n",
       "      <td>241</td>\n",
       "      <td>petrol</td>\n",
       "      <td>no</td>\n",
       "      <td>66</td>\n",
       "      <td>2016-01-04 00:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151423</th>\n",
       "      <td>2016-03-19</td>\n",
       "      <td>16450</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>60000</td>\n",
       "      <td>seat</td>\n",
       "      <td>leon</td>\n",
       "      <td>sedan</td>\n",
       "      <td>manual</td>\n",
       "      <td>241</td>\n",
       "      <td>petrol</td>\n",
       "      <td>no</td>\n",
       "      <td>66</td>\n",
       "      <td>2016-01-04 00:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196428</th>\n",
       "      <td>2016-03-28</td>\n",
       "      <td>8450</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>150000</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>passat</td>\n",
       "      <td>wagon</td>\n",
       "      <td>auto</td>\n",
       "      <td>140</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>no</td>\n",
       "      <td>18</td>\n",
       "      <td>2016-01-04 04:46:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354151</th>\n",
       "      <td>2016-03-28</td>\n",
       "      <td>8450</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>150000</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>passat</td>\n",
       "      <td>wagon</td>\n",
       "      <td>auto</td>\n",
       "      <td>140</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>no</td>\n",
       "      <td>18</td>\n",
       "      <td>2016-01-04 04:46:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234577</th>\n",
       "      <td>2016-03-24</td>\n",
       "      <td>2999</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>150000</td>\n",
       "      <td>bmw</td>\n",
       "      <td>3er</td>\n",
       "      <td>wagon</td>\n",
       "      <td>auto</td>\n",
       "      <td>193</td>\n",
       "      <td>petrol</td>\n",
       "      <td>no</td>\n",
       "      <td>93</td>\n",
       "      <td>2016-01-04 05:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224299</th>\n",
       "      <td>2016-03-24</td>\n",
       "      <td>2999</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>150000</td>\n",
       "      <td>bmw</td>\n",
       "      <td>3er</td>\n",
       "      <td>wagon</td>\n",
       "      <td>auto</td>\n",
       "      <td>193</td>\n",
       "      <td>petrol</td>\n",
       "      <td>no</td>\n",
       "      <td>93</td>\n",
       "      <td>2016-01-04 05:45:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date_created  price  reg_year  reg_month  mileage       brand   model  \\\n",
       "237989   2016-03-19  16450      2009          6    60000        seat    leon   \n",
       "151423   2016-03-19  16450      2009          6    60000        seat    leon   \n",
       "196428   2016-03-28   8450      2007          1   150000  volkswagen  passat   \n",
       "354151   2016-03-28   8450      2007          1   150000  volkswagen  passat   \n",
       "234577   2016-03-24   2999      2000          2   150000         bmw     3er   \n",
       "224299   2016-03-24   2999      2000          2   150000         bmw     3er   \n",
       "\n",
       "       vehicle_type gearbox  power fuel_type not_repaired  postal_region  \\\n",
       "237989        sedan  manual    241    petrol           no             66   \n",
       "151423        sedan  manual    241    petrol           no             66   \n",
       "196428        wagon    auto    140  gasoline           no             18   \n",
       "354151        wagon    auto    140  gasoline           no             18   \n",
       "234577        wagon    auto    193    petrol           no             93   \n",
       "224299        wagon    auto    193    petrol           no             93   \n",
       "\n",
       "            last_seen_date  \n",
       "237989 2016-01-04 00:15:00  \n",
       "151423 2016-01-04 00:15:00  \n",
       "196428 2016-01-04 04:46:00  \n",
       "354151 2016-01-04 04:46:00  \n",
       "234577 2016-01-04 05:45:00  \n",
       "224299 2016-01-04 05:45:00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Investigamos filas duplicadas\n",
    "print(f'Filas duplicadas: {df.duplicated().sum()}')\n",
    "df[df.duplicated(keep=False)].sort_values(by='last_seen_date').head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos filas duplicadas\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamiento de valores ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_created          0\n",
       "price                 0\n",
       "reg_year              0\n",
       "reg_month             0\n",
       "mileage               0\n",
       "brand                 0\n",
       "model             19691\n",
       "vehicle_type      37463\n",
       "gearbox           19821\n",
       "power                 0\n",
       "fuel_type         32874\n",
       "not_repaired      71099\n",
       "postal_region         0\n",
       "last_seen_date        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analizamos valores ausentes\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precio promedio por categoría:\n",
      "not_repaired\n",
      "no     5295.742038\n",
      "yes    1915.973464\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Hipótesis de diferencia de precio\n",
    "print(\"Precio promedio por categoría:\")\n",
    "print(df.groupby('not_repaired')['price'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores ausentes con tratamiento distinto\n",
    "df['not_repaired'].fillna('not_disclosed', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La columna 'not_repaired' se trató de manera diferente ya que tenemos la hipótesis de que la mayoría de los vendedores que no contestan este dato es porque 'sí' fueron reparados pero no quieren que el precio se vea castigado, como se puede observar en los datos de la celda anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_created      0\n",
       "price             0\n",
       "reg_year          0\n",
       "reg_month         0\n",
       "mileage           0\n",
       "brand             0\n",
       "model             0\n",
       "vehicle_type      0\n",
       "gearbox           0\n",
       "power             0\n",
       "fuel_type         0\n",
       "not_repaired      0\n",
       "postal_region     0\n",
       "last_seen_date    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Función para tratar valores ausentes regulares\n",
    "def replace_unknown_null(df):\n",
    "    \"\"\"\n",
    "    Reemplaza los valores ausentes por 'unknown' en columnas descritas.\n",
    "    \"\"\"\n",
    "    columns = ['model', 'vehicle_type', 'gearbox', 'fuel_type']\n",
    "    df[columns] = df[columns].replace(np.nan, 'unknown')\n",
    "    return df\n",
    "\n",
    "\n",
    "# Aplicamos función\n",
    "df = replace_unknown_null(df)\n",
    "\n",
    "# Comprobamos cambios\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamiento de datos incongruentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unificamos nombres de categorías\n",
    "df['brand'] = df['brand'].replace('sonstige_autos', 'others')\n",
    "df['fuel_type'] = df['fuel_type'].replace('petrol', 'gasoline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autos menores al año 1900: 130\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Autos menores al año 1900: {df['reg_year'][df['reg_year'] > 2018].count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autos menores al año 1900: 66\n",
      "Autos mayores al año 2017: 4086\n"
     ]
    }
   ],
   "source": [
    "# Análisis columna 'reg_year'\n",
    "print(\n",
    "    f\"Autos menores al año 1900: {df['reg_year'][df['reg_year'] < 1900].count()}\")\n",
    "print(\n",
    "    f\"Autos mayores al año 2017: {df['reg_year'][df['reg_year'] > 2017].count()}\")\n",
    "# Eliminamos las filas con autos de año menores a 1900 y mayores al año 2017\n",
    "df = df[(df['reg_year'] >= 1900) & (df['reg_year'] <= 2017)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos años incongruentes dado que es imposible tener autos con modelos de años antes de 1900 y despues del año de cuando se tomaron estos datos (2016)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas eliminadas: 11973\n"
     ]
    }
   ],
   "source": [
    "# Las filas con precios menores a '20' euros no sirven para entrenar el modelo, lo sesgan\n",
    "unclean_len = len(df['price'])\n",
    "df = df[df['price'] > 20]\n",
    "clean_len = len(df['price'])\n",
    "print(f'Filas eliminadas: {unclean_len - clean_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos con power = \"0\" ANTES de imputación: 34656\n",
      "Datos con power = \"0\" DESPUES de imputación: 1\n"
     ]
    }
   ],
   "source": [
    "# Relizamos imputación para los valores '0' en la columna 'power'\n",
    "\n",
    "print(\n",
    "    f'Datos con power = \"0\" ANTES de imputación: {len(df[df[\"power\"] == 0])}')\n",
    "\n",
    "# Creamos función de imputación\n",
    "\n",
    "\n",
    "def impute_power_conditional(df, threshold=10):\n",
    "    \"\"\"\n",
    "    Imputa valores de power = 0 usando estrategia condicional\n",
    "    Si no encuentra grupo exacto, usa model como respaldo\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Estadísticas para grupos exactos (5 características)\n",
    "    power_stats = df_copy[df_copy['power'] > 0].groupby(\n",
    "        ['brand', 'model', 'vehicle_type', 'fuel_type', 'gearbox']\n",
    "    )['power'].agg(['mean', 'median', 'count']).round(2)\n",
    "    power_stats_filtered = power_stats[power_stats['count'] > 0]\n",
    "\n",
    "    # Estadísticas de respaldo (model)\n",
    "    backup_stats = df_copy[df_copy['power'] > 0].groupby('model'\n",
    "                                                         )['power'].agg(['mean', 'median', 'count']).round(2)\n",
    "    backup_stats_filtered = backup_stats[backup_stats['count'] > 0]\n",
    "\n",
    "    # Aplicamos imputación\n",
    "    for index, row in df_copy[df_copy['power'] == 0].iterrows():\n",
    "        try:\n",
    "            # Grupo exacto (todas las características)\n",
    "            group_key = (row['brand'], row['model'], row['vehicle_type'],\n",
    "                         row['fuel_type'], row['gearbox'])\n",
    "\n",
    "            if group_key in power_stats_filtered.index:\n",
    "                stats = power_stats_filtered.loc[group_key]\n",
    "                mean_val = stats['mean']\n",
    "                median_val = stats['median']\n",
    "                difference = abs(mean_val - median_val)\n",
    "\n",
    "                # Condicional para elegir media o mediana\n",
    "                if difference > threshold:\n",
    "                    impute_value = median_val\n",
    "                else:\n",
    "                    impute_value = mean_val\n",
    "\n",
    "                df_copy.loc[index, 'power'] = impute_value\n",
    "\n",
    "            else:\n",
    "                # Respaldo (solo model)\n",
    "                backup_key = row['model']\n",
    "\n",
    "                if backup_key in backup_stats_filtered.index:\n",
    "                    backup_stats_row = backup_stats_filtered.loc[backup_key]\n",
    "                    backup_mean = backup_stats_row['mean']\n",
    "                    backup_median = backup_stats_row['median']\n",
    "                    backup_difference = abs(backup_mean - backup_median)\n",
    "\n",
    "                    # Condicional para elegir media o mediana\n",
    "                    if backup_difference > threshold:\n",
    "                        impute_value = backup_median\n",
    "                    else:\n",
    "                        impute_value = backup_mean\n",
    "\n",
    "                    df_copy.loc[index, 'power'] = impute_value\n",
    "\n",
    "        except KeyError:\n",
    "            # Si tampoco encuentra el respaldo, continuar sin imputar\n",
    "            continue\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "# Aplicamos imputación\n",
    "df_clean = impute_power_conditional(df)\n",
    "print(\n",
    "    f'Datos con power = \"0\" DESPUES de imputación: {len(df_clean[df_clean[\"power\"] == 0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Después de la prueba exitosa sobreescribimos el dataset original\n",
    "df = df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos imputación con media o mediana según sea el caso ya que la columna 'power' contenía más del 10% de datos en '0', y eso estaba sesgando nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos con model = \"unknown\" ANTES de imputación: 16614\n",
      "Datos con model = \"unknown\" DESPUES de imputación: 2678\n"
     ]
    }
   ],
   "source": [
    "# Imputación para los valores 'unknown' en la columna 'model'\n",
    "print(\n",
    "    f'Datos con model = \"unknown\" ANTES de imputación: {len(df[df[\"model\"] == \"unknown\"])}')\n",
    "\n",
    "\n",
    "def impute_model_conditional(df, threshold=10):\n",
    "    \"\"\"\n",
    "    Imputa valores de model = 'unknown' usando estrategia condicional\n",
    "    Si no encuentra grupo exacto, usa brand como respaldo\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Estadísticas para grupos exactos (4 características)\n",
    "    model_stats = df_copy[df_copy['model'] != 'unknown'].groupby(\n",
    "        ['brand', 'vehicle_type', 'fuel_type', 'gearbox']\n",
    "    )['model'].agg(lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 'unknown')\n",
    "\n",
    "    # Estadísticas de respaldo (brand + vehicle type)\n",
    "    backup_stats = df_copy[df_copy['model'] != 'unknown'].groupby(['brand', 'vehicle_type']\n",
    "                                                                  )['model'].agg(lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 'unknown')\n",
    "\n",
    "    # Aplicamos imputación\n",
    "    for index, row in df_copy[df_copy['model'] == 'unknown'].iterrows():\n",
    "        try:\n",
    "            # Grupo exacto (todas las características)\n",
    "            group_key = (row['brand'], row['vehicle_type'], row['fuel_type'],\n",
    "                         row['gearbox'])\n",
    "\n",
    "            if group_key in model_stats.index:\n",
    "                impute_value = model_stats.loc[group_key]\n",
    "                df_copy.loc[index, 'model'] = impute_value\n",
    "\n",
    "            else:\n",
    "                # Respaldo (brand + vehicle type)\n",
    "                backup_key = (row['brand'], row['vehicle_type'])\n",
    "\n",
    "                if backup_key in backup_stats.index:\n",
    "                    impute_value = backup_stats.loc[backup_key]\n",
    "                    df_copy.loc[index, 'model'] = impute_value\n",
    "\n",
    "        except KeyError:\n",
    "            # Si tampoco encuentra el respaldo, continuar sin imputar\n",
    "            continue\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "# Aplicamos imputación\n",
    "df_clean = impute_model_conditional(df)\n",
    "print(\n",
    "    f'Datos con model = \"unknown\" DESPUES de imputación: {len(df_clean[df_clean[\"model\"] == \"unknown\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Después de la prueba exitosa sobreescribimos el dataset original\n",
    "df = df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos imputación para model = 'unknown' con las características 'brand', 'vehicle_type', 'fuel_type' y 'gearbox' ya que tenemos más de 16 mil filas que no sabemos el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 337162 entries, 0 to 354368\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count   Dtype         \n",
      "---  ------          --------------   -----         \n",
      " 0   date_created    337162 non-null  datetime64[ns]\n",
      " 1   price           337162 non-null  float64       \n",
      " 2   reg_year        337162 non-null  int64         \n",
      " 3   reg_month       337162 non-null  int64         \n",
      " 4   mileage         337162 non-null  int64         \n",
      " 5   brand           337162 non-null  category      \n",
      " 6   model           337162 non-null  category      \n",
      " 7   vehicle_type    337162 non-null  category      \n",
      " 8   gearbox         337162 non-null  category      \n",
      " 9   power           337162 non-null  float64       \n",
      " 10  fuel_type       337162 non-null  category      \n",
      " 11  not_repaired    337162 non-null  category      \n",
      " 12  postal_region   337162 non-null  category      \n",
      " 13  last_seen_date  337162 non-null  datetime64[ns]\n",
      "dtypes: category(7), datetime64[ns](2), float64(2), int64(3)\n",
      "memory usage: 31.2 MB\n"
     ]
    }
   ],
   "source": [
    "# Cambio de tipos de datos\n",
    "df['price'] = df['price'].astype(float)\n",
    "categorical_columns = ['brand', 'model', 'vehicle_type',\n",
    "                       'gearbox', 'fuel_type', 'not_repaired', 'postal_region']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    df[col] = df[col].astype('category')\n",
    "\n",
    "# Comprobar cambios\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de los modelos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentamos los datos en entrenamiento y prueba\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random = 23451\n",
    "df_train, df_test = train_test_split(df, test_size=0.30, random_state=random)\n",
    "\n",
    "features_train = df_train.drop(\n",
    "    ['date_created', 'price', 'last_seen_date'], axis=1)\n",
    "target_train = df_train['price']\n",
    "features_test = df_test.drop(\n",
    "    ['date_created', 'price', 'last_seen_date'], axis=1)\n",
    "target_test = df_test['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lans_\\anaconda3\\envs\\tripleten\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] El sistema no puede encontrar el archivo especificado\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\lans_\\anaconda3\\envs\\tripleten\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "  File \"c:\\Users\\lans_\\anaconda3\\envs\\tripleten\\lib\\subprocess.py\", line 493, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "  File \"c:\\Users\\lans_\\anaconda3\\envs\\tripleten\\lib\\subprocess.py\", line 858, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"c:\\Users\\lans_\\anaconda3\\envs\\tripleten\\lib\\subprocess.py\", line 1327, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "c:\\Users\\lans_\\anaconda3\\envs\\tripleten\\lib\\site-packages\\lightgbm\\basic.py:2108: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  _log_warning(\n",
      "c:\\Users\\lans_\\anaconda3\\envs\\tripleten\\lib\\site-packages\\lightgbm\\basic.py:2130: UserWarning: categorical_feature in param dict is overridden.\n",
      "  _log_warning(f\"{cat_alias} in param dict is overridden.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 20 s\n",
      "Wall time: 1.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# PRIMEROS HIPERPARÁMETROS\n",
    "# Entrenamos modelo con LightGBM \n",
    "import lightgbm as lgb\n",
    "\n",
    "# Definimos columnas categóricas\n",
    "lgb_features = ['brand', 'model', 'vehicle_type', 'gearbox', 'fuel_type', 'not_repaired', 'postal_region']\n",
    "\n",
    "# Elegimos hiperparámetros\n",
    "model_lgb_first = lgb.LGBMRegressor(n_estimators=500,\n",
    "                              num_leaves=31,\n",
    "                              learning_rate=0.1,\n",
    "                              categorical_feature=lgb_features,\n",
    "                              metric='RMSE',\n",
    "                              verbose=-1\n",
    "                              )\n",
    "\n",
    "# Entrenamos modelo\n",
    "start_time = time.time()\n",
    "model_lgb_first.fit(features_train, target_train)\n",
    "end_time = time.time()\n",
    "training_time_lgb_first = end_time - start_time\n",
    "\n",
    "# Predecimos modelo\n",
    "start_time = time.time()\n",
    "pred_lgb_first = model_lgb_first.predict(features_test)\n",
    "end_time = time.time()\n",
    "pred_time_lgb_first = end_time - start_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 34.1 s\n",
      "Wall time: 2.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# SEGUNDOS HIPERPARÁMETROS\n",
    "# Entrenamos modelo con LightGBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Definimos columnas categóricas\n",
    "lgb_features = ['brand', 'model', 'vehicle_type', 'gearbox', 'fuel_type', 'not_repaired', 'postal_region']\n",
    "\n",
    "# Elegimos hiperparámetros\n",
    "model_lgb_second = lgb.LGBMRegressor(n_estimators=700,\n",
    "                              num_leaves=50,\n",
    "                              learning_rate=0.15,\n",
    "                              categorical_feature=lgb_features,\n",
    "                              metric='RMSE',\n",
    "                              verbose=-1\n",
    "                              )\n",
    "\n",
    "# Entrenamos modelo\n",
    "start_time = time.time()\n",
    "model_lgb_second.fit(features_train, target_train)\n",
    "end_time = time.time()\n",
    "training_time_lgb_second = end_time - start_time\n",
    "\n",
    "# Predecimos modelo\n",
    "start_time = time.time()\n",
    "pred_lgb_second = model_lgb_second.predict(features_test)\n",
    "end_time = time.time()\n",
    "pred_time_lgb_second = end_time - start_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 4954.9877069\ttotal: 240ms\tremaining: 1m 59s\n",
      "100:\tlearn: 1982.5875471\ttotal: 11s\tremaining: 43.3s\n",
      "200:\tlearn: 1882.1630459\ttotal: 21.1s\tremaining: 31.4s\n",
      "300:\tlearn: 1828.8324621\ttotal: 31.5s\tremaining: 20.8s\n",
      "400:\tlearn: 1800.7221537\ttotal: 41.9s\tremaining: 10.3s\n",
      "499:\tlearn: 1780.4813593\ttotal: 52.4s\tremaining: 0us\n",
      "CPU times: total: 6min 44s\n",
      "Wall time: 52.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Entrenamos modelo con CatBoost\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Definimos columnas categóricas\n",
    "cat_features = ['brand', 'model', 'vehicle_type', 'gearbox', 'fuel_type', 'not_repaired', 'postal_region']\n",
    "\n",
    "# Elegimos hiperparámetros\n",
    "model_catb = CatBoostRegressor(random_seed=random,\n",
    "                               iterations=500,\n",
    "                               depth=6,\n",
    "                              learning_rate=0.1,\n",
    "                              loss_function='Quantile:alpha=0.4',\n",
    "                              eval_metric='RMSE',\n",
    "                               cat_features=cat_features,\n",
    "                               verbose=100\n",
    "                              )\n",
    "\n",
    "# Entrenamos modelo\n",
    "start_time = time.time()\n",
    "model_catb.fit(features_train, target_train)\n",
    "end_time = time.time()\n",
    "training_time_catb = end_time - start_time\n",
    "\n",
    "# Predecimos modelo\n",
    "start_time = time.time()\n",
    "pred_catb = model_catb.predict(features_test)\n",
    "end_time = time.time()\n",
    "pred_time_catb = end_time - start_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5.14 s\n",
      "Wall time: 705 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Entrenamos modelo con XGboost\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Codificamos las variables categóricas\n",
    "features_train_enc = features_train.copy()\n",
    "features_test_enc = features_test.copy()\n",
    "\n",
    "categorical_cols = ['brand', 'model', 'vehicle_type', 'gearbox', 'fuel_type', 'not_repaired', 'postal_region']\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    # Ajustamos con todos los datos (train + test) para evitar problemas\n",
    "    all_values = pd.concat([features_train_enc[col], features_test_enc[col]])\n",
    "    le.fit(all_values)\n",
    "     \n",
    "    features_train_enc[col] = le.transform(features_train_enc[col])\n",
    "    features_test_enc[col] = le.transform(features_test_enc[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "\n",
    "# Elegimos hiperparámetros\n",
    "model_xgb = xgb.XGBRegressor(random_state=random,\n",
    "                             iterations=500,\n",
    "                              learning_rate=0.1,\n",
    "                              max_leaves=31,\n",
    "                              eval_metric='rmse',\n",
    "                               verbosity=0\n",
    "                              )\n",
    "\n",
    "# Entrenamos modelo\n",
    "start_time = time.time()\n",
    "model_xgb.fit(features_train_enc, target_train)\n",
    "end_time = time.time()\n",
    "training_time_xgb = end_time - start_time\n",
    "\n",
    "# Predecimos modelo\n",
    "start_time = time.time()\n",
    "pred_xgb = model_xgb.predict(features_test_enc)\n",
    "end_time = time.time()\n",
    "pred_time_xgb = end_time - start_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 37s\n",
      "Wall time: 15.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# PRIMEROS HIPERPARÁMETROS\n",
    "# Entrenamos modelo de Bosque aleatorio\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Elegimos hiperparámetros\n",
    "model_forest_first = RandomForestRegressor(random_state=random,\n",
    "                                     n_estimators=500,\n",
    "                                     max_depth=None,\n",
    "                                     max_leaf_nodes=31,\n",
    "                                     min_samples_split=2,\n",
    "                                     min_samples_leaf=1,\n",
    "                                     n_jobs=-1,\n",
    "                                     verbose=0\n",
    "                                    )\n",
    "\n",
    "# Entrenamos modelo\n",
    "start_time = time.time()\n",
    "model_forest_first.fit(features_train_enc, target_train)\n",
    "end_time = time.time()\n",
    "training_time_forest_first = end_time - start_time\n",
    "\n",
    "# Predecimos modelo\n",
    "start_time = time.time()\n",
    "pred_forest_first = model_forest_first.predict(features_test_enc)\n",
    "end_time = time.time()\n",
    "pred_time_forest_first = end_time - start_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 7min 46s\n",
      "Wall time: 31.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# SEGUNDOS HIPERPARÁMETROS\n",
    "# Entrenamos modelo de Bosque aleatorio\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Elegimos hiperparámetros\n",
    "model_forest_second = RandomForestRegressor(random_state=random,\n",
    "                                     n_estimators=1000,\n",
    "                                     max_depth=None,\n",
    "                                     max_leaf_nodes=50,\n",
    "                                     min_samples_split=2,\n",
    "                                     min_samples_leaf=1,\n",
    "                                     n_jobs=-1,\n",
    "                                     verbose=0\n",
    "                                    )\n",
    "\n",
    "# Entrenamos modelo\n",
    "start_time = time.time()\n",
    "model_forest_second.fit(features_train_enc, target_train)\n",
    "end_time = time.time()\n",
    "training_time_forest_second = end_time - start_time\n",
    "\n",
    "# Predecimos modelo\n",
    "start_time = time.time()\n",
    "pred_forest_second = model_forest_second.predict(features_test_enc)\n",
    "end_time = time.time()\n",
    "pred_time_forest_second = end_time - start_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 359 ms\n",
      "Wall time: 352 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Entrenamos modelo de Árbol de decisión\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Elegimos hiperparámetros\n",
    "model_tree = DecisionTreeRegressor(random_state=random,\n",
    "                                   max_depth=None,\n",
    "                                   max_leaf_nodes=31,\n",
    "                                   min_samples_split=2,\n",
    "                                   min_samples_leaf=1,\n",
    "                                   criterion='squared_error'\n",
    "                                  )\n",
    "\n",
    "# Entrenamos modelo\n",
    "start_time = time.time()\n",
    "model_tree.fit(features_train_enc, target_train)\n",
    "end_time = time.time()\n",
    "training_time_tree = end_time - start_time\n",
    "\n",
    "# Predecimos modelo\n",
    "start_time = time.time()\n",
    "pred_tree = model_tree.predict(features_test_enc)\n",
    "end_time = time.time()\n",
    "pred_time_tree = end_time - start_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 62.5 ms\n",
      "Wall time: 62.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Entrenamos modelo de Regresión lineal\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Elegimos hiperparámetros\n",
    "model_lr = LinearRegression()\n",
    "\n",
    "# Entrenamos modelo\n",
    "start_time = time.time()\n",
    "model_lr.fit(features_train_enc, target_train)\n",
    "end_time = time.time()\n",
    "training_time_lr = end_time - start_time\n",
    "\n",
    "# Predecimos modelo\n",
    "start_time = time.time()\n",
    "pred_lr = model_lr.predict(features_test_enc)\n",
    "end_time = time.time()\n",
    "pred_time_lr = end_time - start_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculos de RMSE por modelo\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse_lgb_first = mean_squared_error(target_test, pred_lgb_first, squared=False)\n",
    "rmse_lgb_second = mean_squared_error(\n",
    "    target_test, pred_lgb_second, squared=False)\n",
    "rmse_catb = mean_squared_error(target_test, pred_catb, squared=False)\n",
    "rmse_xgb = mean_squared_error(target_test, pred_xgb, squared=False)\n",
    "rmse_forest_first = mean_squared_error(\n",
    "    target_test, pred_forest_first, squared=False)\n",
    "rmse_forest_second = mean_squared_error(\n",
    "    target_test, pred_forest_second, squared=False)\n",
    "rmse_tree = mean_squared_error(target_test, pred_tree, squared=False)\n",
    "rmse_lr = mean_squared_error(target_test, pred_lr, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELO LIGHTGBM:\n",
      " Primeros parámetros:\n",
      "  RECM: 1620.44\n",
      "  Tiempo de entrenamiento: 1.1788 segundos.\n",
      "  Tiempo de predicción: 0.234 segundos.\n",
      " Segundos parámetros:\n",
      "  RECM: 1601.24\n",
      "  Tiempo de entrenamiento: 1.9686 segundos.\n",
      "  Tiempo de predicción: 0.3472 segundos.\n",
      "\n",
      "MODELO CATBOOST:\n",
      "  RECM: 1803.98\n",
      "  Tiempo de entrenamiento: 52.8193 segundos.\n",
      "  Tiempo de predicción: 0.0526 segundos.\n",
      "\n",
      "MODELO XGBOOST:\n",
      "  RECM: 1799.03\n",
      "  Tiempo de entrenamiento: 0.3211 segundos.\n",
      "  Tiempo de predicción: 0.0336 segundos.\n",
      "\n",
      "MODELO RANDOM FOREST:\n",
      " Primeros parámetros:\n",
      "  RECM: 2376.1\n",
      "  Tiempo de entrenamiento: 14.8361 segundos.\n",
      "  Tiempo de predicción: 0.1737 segundos.\n",
      " Segundos parámetros:\n",
      "  RECM: 2271.27\n",
      "  Tiempo de entrenamiento: 30.8078 segundos.\n",
      "  Tiempo de predicción: 0.3184 segundos.\n",
      "\n",
      "MODELO ÁRBOL DE DECISIÓN:\n",
      "  RECM: 2403.4\n",
      "  Tiempo de entrenamiento: 0.3458 segundos.\n",
      "  Tiempo de predicción: 0.006 segundos.\n",
      "\n",
      "MODELO DE REGRESIÓN LINEAL:\n",
      "  RECM: 3559.26\n",
      "  Tiempo de entrenamiento: 0.0587 segundos.\n",
      "  Tiempo de predicción: 0.004 segundos.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Presentación de métricas\n",
    "print(f'MODELO LIGHTGBM:')\n",
    "print(f' Primeros parámetros:')\n",
    "print(f'  RECM: {rmse_lgb_first.round(2)}\\n  Tiempo de entrenamiento: {round(training_time_lgb_first, 4)} segundos.\\n  Tiempo de predicción: {round(pred_time_lgb_first, 4)} segundos.')\n",
    "print(f' Segundos parámetros:')\n",
    "print(f'  RECM: {rmse_lgb_second.round(2)}\\n  Tiempo de entrenamiento: {round(training_time_lgb_second, 4)} segundos.\\n  Tiempo de predicción: {round(pred_time_lgb_second, 4)} segundos.\\n')\n",
    "print(f'MODELO CATBOOST:')\n",
    "print(f'  RECM: {rmse_catb.round(2)}\\n  Tiempo de entrenamiento: {round(training_time_catb, 4)} segundos.\\n  Tiempo de predicción: {round(pred_time_catb, 4)} segundos.\\n')\n",
    "print(f'MODELO XGBOOST:')\n",
    "print(f'  RECM: {rmse_xgb.round(2)}\\n  Tiempo de entrenamiento: {round(training_time_xgb, 4)} segundos.\\n  Tiempo de predicción: {round(pred_time_xgb, 4)} segundos.\\n')\n",
    "print(f'MODELO RANDOM FOREST:')\n",
    "print(f' Primeros parámetros:')\n",
    "print(f'  RECM: {rmse_forest_first.round(2)}\\n  Tiempo de entrenamiento: {round(training_time_forest_first, 4)} segundos.\\n  Tiempo de predicción: {round(pred_time_forest_first, 4)} segundos.')\n",
    "print(f' Segundos parámetros:')\n",
    "print(f'  RECM: {rmse_forest_second.round(2)}\\n  Tiempo de entrenamiento: {round(training_time_forest_second, 4)} segundos.\\n  Tiempo de predicción: {round(pred_time_forest_second, 4)} segundos.\\n')\n",
    "print(f'MODELO ÁRBOL DE DECISIÓN:')\n",
    "print(f'  RECM: {rmse_tree.round(2)}\\n  Tiempo de entrenamiento: {round(training_time_tree, 4)} segundos.\\n  Tiempo de predicción: {round(pred_time_tree, 4)} segundos.\\n')\n",
    "print(f'MODELO DE REGRESIÓN LINEAL:')\n",
    "print(f'  RECM: {rmse_lr.round(2)}\\n  Tiempo de entrenamiento: {round(training_time_lr, 4)} segundos.\\n  Tiempo de predicción: {round(pred_time_lr, 4)} segundos.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos los modelos de potenciación del gradiente son más efeiciente en cuanto que los demás modelos. En resumen el modelo de potenciación del gradiente LightGBM utilizando los segundos parámetros es el más eficiente en cuanto al tiempo de entrenamiento y calidad de la predicción en comparación con los otros modelos.  \n",
    "\n",
    "El modelo de potenciación del gradiente es **LightGBM** es el mejor en las 3 métricas solicitadas:\n",
    "- La calidad de predicción del modelo.\n",
    "- El tiempo utilizado en entrenarlo.\n",
    "- La velocidad para predecir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versiones de las librerías:\n",
      "python==3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]\n",
      "numpy==1.23.5\n",
      "pandas==1.2.4\n",
      "seaborn==0.13.2\n",
      "sklearn==1.3.2\n",
      "lightgbm==4.4.0\n",
      "catboost==1.2.5\n",
      "xgboost==2.1.1\n"
     ]
    }
   ],
   "source": [
    "# Versiones de librerías\n",
    "import sys\n",
    "print(\"Versiones de las librerías:\")\n",
    "print(f\"python=={sys.version}\")\n",
    "print(f\"numpy=={np.__version__}\")\n",
    "print(f\"pandas=={pd.__version__}\")\n",
    "print(f\"seaborn=={sns.__version__}\")\n",
    "print(f\"sklearn=={sklearn.__version__}\")\n",
    "print(f\"lightgbm=={lgb.__version__}\")\n",
    "print(f\"catboost=={catboost.__version__}\")\n",
    "print(f\"xgboost=={xgb.__version__}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tripleten",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
